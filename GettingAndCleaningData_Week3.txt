## http://statmethods.net/management/functions.html
## http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf

## ------------------------ Subsetting and sorting ---------------------------- ##
> set.seed(13435)
> X<-data.frame("var1"=sample(1:5), "var2"=sample(6:10), "var3"=sample(11:15))
> X
  var1 var2 var3
1    2    8   15
2    3    7   12
3    5    6   14
4    1   10   11
5    4    9   13

> X<-X[sample(1:5),]
> X$var2[c(1,3)]=NA
> X
  var1 var2 var3
4    1   NA   11
1    2    8   15
5    4   NA   13
3    5    6   14
2    3    7   12
> 

> X[,1]			## getting column
[1] 1 2 4 5 3
> X[,"var1"]	## getting column
[1] 1 2 4 5 3	
> 
> X[1:2, "var2"]## getting first and second row of column 2 (var2)
[1] NA  8
> 
> X[(X$var1<=3 & X$var3 > 11),]	## condition with AND
  var1 var2 var3
1    2    8   15
2    3    7   12
> X[(X$var1<=3 | X$var3 > 15),]	## condition with OR
  var1 var2 var3
4    1   NA   11
1    2    8   15
2    3    7   12

> X[which(X$var2 > 6),]	## ignores NA
  var1 var2 var3
1    2    8   15
2    3    7   12

> sort(X$var1)						## sort column
[1] 1 2 3 4 5
> sort(X$var1, decreasing=TRUE)		## sort with order
[1] 5 4 3 2 1
> sort(X$var2, na.last=TRUE)		## sort with NA
[1]  6  7  8 NA NA
> sort(X$var2, decreasing=TRUE, na.last=TRUE)
[1]  8  7  6 NA NA

> X[order(X$var1),]					## order rows by column value
  var1 var2 var3
4    1   NA   11
1    2    8   15
2    3    7   12
5    4   NA   13
3    5    6   14

> X[order(X$var1, X$var3),]			## multiple order by columns

##		plyr ##
> library(plyr)
> arrange(X,var1)					## order by column
  var1 var2 var3
1    1   NA   11
2    2    8   15
3    3    7   12
4    4   NA   13
5    5    6   14
> arrange(X,desc(var1))				## order by column with ACS/DESC
  var1 var2 var3
1    5    6   14
2    4   NA   13
3    3    7   12
4    2    8   15
5    1   NA   11
> 

> X$var4 <- rnorm(5)			## add column to data.frame
> X
  var1 var2 var3        var4
4    1   NA   11 -0.02166735
1    2    8   15 -0.17411953
5    4   NA   13  0.23900438
3    5    6   14 -1.83245959
2    3    7   12 -0.03718739
> 
> Y<-cbind(rnorm(5), X)			## add column. New data.frame is created
> Y
    rnorm(5) var1 var2 var3        var4
4 -0.4405170    1   NA   11 -0.02166735
1 -1.4482636    2    8   15 -0.17411953
5 -0.5182457    4   NA   13  0.23900438
3  0.7585272    5    6   14 -1.83245959
2  0.2849353    3    7   12 -0.03718739
> 
> Z<-rbind(Y,rnorm(5))			## add row. New data.frame is created
> Z
    rnorm(5)       var1       var2      var3        var4
4 -0.4405170  1.0000000         NA 11.000000 -0.02166735
1 -1.4482636  2.0000000  8.0000000 15.000000 -0.17411953
5 -0.5182457  4.0000000         NA 13.000000  0.23900438
3  0.7585272  5.0000000  6.0000000 14.000000 -1.83245959
2  0.2849353  3.0000000  7.0000000 12.000000 -0.03718739
6 -1.5378398 -0.3652188 -0.4338298 -1.577484 -1.34954882


## ----------------------- Summarizing Data ------------------------ ##
> fileUrl<-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
> download.file(fileUrl, destfile=".\\data\\restaurant.csv")
> restData<-read.csv(".\\data\\restaurant.csv")
> head(restData, n=3)
> tail(restData, n=3)
> summary(restData)
                           name         zipCode             neighborhood
 MCDONALD'S                  :   8   Min.   :-21226   Downtown    :128  
 POPEYES FAMOUS FRIED CHICKEN:   7   1st Qu.: 21202   Fells Point : 91  
 SUBWAY                      :   6   Median : 21218   Inner Harbor: 89  
 KENTUCKY FRIED CHICKEN      :   5   Mean   : 21185   Canton      : 81  
 BURGER KING                 :   4   3rd Qu.: 21226   Federal Hill: 42  
 DUNKIN DONUTS               :   4   Max.   : 21287   Mount Vernon: 33  
 (Other)                     :1293                    (Other)     :863  
 councilDistrict       policeDistrict                          Location.1    
 Min.   : 1.000   SOUTHEASTERN:385    1101 RUSSELL ST\nBaltimore, MD\n:   9  
 1st Qu.: 2.000   CENTRAL     :288    201 PRATT ST\nBaltimore, MD\n   :   8  
 Median : 9.000   SOUTHERN    :213    2400 BOSTON ST\nBaltimore, MD\n :   8  
 Mean   : 7.191   NORTHERN    :157    300 LIGHT ST\nBaltimore, MD\n   :   5  
 3rd Qu.:11.000   NORTHEASTERN: 72    300 CHARLES ST\nBaltimore, MD\n :   4  
 Max.   :14.000   EASTERN     : 67    301 LIGHT ST\nBaltimore, MD\n   :   4  
                  (Other)     :145    (Other)                         :1289  
> 
> str(restData)
'data.frame':	1327 obs. of  6 variables:
 $ name           : Factor w/ 1277 levels "#1 CHINESE KITCHEN",..: 9 3 998 1 2 4 5 6 7 8 ...
 $ zipCode        : int  21206 21231 21224 21211 21223 21218 21205 21211 21205 21231 ...
 $ neighborhood   : Factor w/ 173 levels "Abell","Arlington",..: 53 52 18 66 104 33 98 133 98 157 ...
 $ councilDistrict: int  2 1 1 14 9 14 13 7 13 1 ...
 $ policeDistrict : Factor w/ 9 levels "CENTRAL","EASTERN",..: 3 6 6 4 8 3 6 4 6 6 ...
 $ Location.1     : Factor w/ 1210 levels "1 BIDDLE ST\nBaltimore, MD\n",..: 835 334 554 755 492 537 505 530 507 569 ..
 
 > quantile(restData$councilDistrict, na.rm=TRUE)
  0%  25%  50%  75% 100% 
   1    2    9   11   14 
> quantile(restData$councilDistrict, na.rm=TRUE, probs=c(0.5, 0.75, 0.95))
50% 75% 95% 
  9  11  13 
> 
> table(restData$zipCode, useNA="ifany") ## with NA values, if they exist

-21226  21201  21202  21205  21206  21207  21208  21209  21210  21211  21212 
     1    136    201     27     30      4      1      8     23     41     28 
 21213  21214  21215  21216  21217  21218  21220  21222  21223  21224  21225 
    31     17     54     10     32     69      1      7     56    199     19 
 21226  21227  21229  21230  21231  21234  21237  21239  21251  21287 
    18      4     13    156    127      7      1      3      2      1 
> 
> table(restData$councilDistrict, restData$zipCode)
    
     -21226 21201 21202 21205 21206 21207 21208 21209 21210 21211 21212 21213
  1       0     0    37     0     0     0     0     0     0     0     0     2
  2       0     0     0     3    27     0     0     0     0     0     0     0
  3       0     0     0     0     0     0     0     0     0     0     0     2
  4       0     0     0     0     0     0     0     0     0     0    27     0
  5       0     0     0     0     0     3     0     6     0     0     0     0
  6       0     0     0     0     0     0     0     1    19     0     0     0
  7       0     0     0     0     0     0     0     1     0    27     0     0
  8       0     0     0     0     0     1     0     0     0     0     0     0
  9       0     1     0     0     0     0     0     0     0     0     0     0
  10      1     0     1     0     0     0     0     0     0     0     0     0
  11      0   115   139     0     0     0     1     0     0     0     1     0
  12      0    20    24     4     0     0     0     0     0     0     0    13
  13      0     0     0    20     3     0     0     0     0     0     0    13
  14      0     0     0     0     0     0     0     0     4    14     0     1
  
> sum(is.na(restData$councilDistrict))		## sums number of NA values in particular column
[1] 0
> any(is.na(restData$councilDistrict))		## shows if there is at least one NA in a particular column
[1] FALSE
> all(restData$zipCode > 0)					## if all value satisfy the condition 
[1] FALSE

> colSums(is.na(restData))					## sums by columns (colRows)
           name         zipCode    neighborhood councilDistrict  policeDistrict 
              0               0               0               0               0 
     Location.1 
              0 
			  
> all(colSums(is.na(restData))==0)			## all colSums are equal to 0
[1] TRUE

> table(restData$zipCode %in% c("21212", "21213"))	## value in range

FALSE  TRUE 
 1268    59 
> 

> restData[restData$zipCode %in% c("21212", "21213"), ]		## subseting data.frame where zipCode values are "21212", "21213"
                                     name zipCode                neighborhood
29                      BAY ATLANTIC CLUB   21212                    Downtown
39                            BERMUDA BAR   21213               Broadway East
92                              ATWATER'S   21212   Chinquapin Park-Belvedere
111            BALTIMORE ESTONIAN SOCIETY   21213          South Clifton Park
187                              CAFE ZEN   21212                    Rosebank
220                   CERIELLO FINE FOODS   21212   Chinquapin Park-Belvedere
266    CLIFTON PARK GOLF COURSE SNACK BAR   21213                 Darley Park
276                CLUB HOUSE BAR & GRILL   21213 Orangeville Industrial Area
289                 CLUBHOUSE BAR & GRILL   21213 Orangeville Industrial Area
291                           COCKY LOU'S   21213               Broadway East
362       DREAM TAVERN, CARRIBEAN  U.S.A.   21213               Broadway East
373                         DUNKIN DONUTS   21212                    Homeland
383        EASTSIDE  SPORTS  SOCIAL  CLUB   21213               Broadway East
417                      FIELDS OLD TRAIL   21212                  Mid-Govans

##  Cross tabs
> data(UCBAdmissions)
> DF <- as.data.frame(UCBAdmissions)
> summary(DF)
      Admit       Gender   Dept       Freq      
 Admitted:12   Male  :12   A:4   Min.   :  8.0  
 Rejected:12   Female:12   B:4   1st Qu.: 80.0  
                           C:4   Median :170.0  
                           D:4   Mean   :188.6  
                           E:4   3rd Qu.:302.5  
                           F:4   Max.   :512.0  
> xt<-xtabs(Freq~Gender+Admit,data=DF)
> xt
        Admit
Gender   Admitted Rejected
  Male       1198     1493
  Female      557     1278
> xt1<-xtabs(Freq~Admit+Gender,data=DF)
> xt1
          Gender
Admit      Male Female
  Admitted 1198    557
  Rejected 1493   1278

  
> head(warpbreaks)
  breaks wool tension
1     26    A       L
2     30    A       L
3     54    A       L
4     25    A       L
5     70    A       L
6     52    A       L
> summary(warpbreaks)
     breaks      wool   tension
 Min.   :10.00   A:27   L:18   
 1st Qu.:18.25   B:27   M:18   
 Median :26.00          H:18   
 Mean   :28.15                 
 3rd Qu.:34.00                 
 Max.   :70.00                 
> warpbreaks$replicate<-rep(1:9, len = 54)
> xt3= xtabs(breaks~.,data=warpbreaks)
> xt3
, , replicate = 1

    tension
wool  L  M  H
   A 26 18 36
   B 27 42 20

, , replicate = 2

    tension
wool  L  M  H
   A 30 21 21
   B 14 26 21

, , replicate = 3

    tension
wool  L  M  H
   A 54 29 24
   B 29 19 24
 
 > ftable(xt3)		## flat table
             replicate  1  2  3  4  5  6  7  8  9
wool tension                                     
A    L                 26 30 54 25 70 52 51 26 67
     M                 18 21 29 17 12 18 35 30 36
     H                 36 21 24 18 10 43 28 15 26
B    L                 27 14 29 19 29 31 41 20 44
     M                 42 26 19 16 39 28 21 39 29
     H                 20 21 24 17 13 15 15 16 28
> 

> fakeData = rnorm(1e5)
> object.size(fakeData)						## size of the object
800040 bytes
> print(object.size(fakeData), units="Mb")
0.8 Mb
> 

## ------------------------ Creating variables --------------------- ##
Missingness indicator
"Cutting up" quantitative variablesApplying transforms

## sequence
> s1<-seq(1,10, by =2); s1
[1] 1 3 5 7 9
> s2<-seq(1,10,length=3);s2
[1]  1.0  5.5 10.0
> x<-c(1,3,8,25,100); seq(along=x)
[1] 1 2 3 4 5

> restData$nearMe <- restData$neighborhood %in% c("Roland Park", "Homeland")
> table(restData$nearMe)

FALSE  TRUE 
 1314    13 
> 

> restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)		## condition, condition true, condition false
> table(restData$zipWrong, restData$zipCode < 0)
       
        FALSE TRUE
  FALSE  1326    0
  TRUE      0    1
> 


##v cut - cutting provides factor variables
> restData$zipCodeGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))	## categorical  variable
> table(restData$zipCodeGroups)

(-2.123e+04,2.12e+04]  (2.12e+04,2.122e+04] (2.122e+04,2.123e+04] 
                  337                   375                   282 
(2.123e+04,2.129e+04] 
                  332 

> table(restData$zipCodeGroups, restData$zipCode)			## zipCodeGroups and zipCode
                       
                        -21226 21201 21202 21205 21206 21207 21208 21209 21210
  (-2.123e+04,2.12e+04]      0   136   201     0     0     0     0     0     0
  (2.12e+04,2.122e+04]       0     0     0    27    30     4     1     8    23
  (2.122e+04,2.123e+04]      0     0     0     0     0     0     0     0     0
  (2.123e+04,2.129e+04]      0     0     0     0     0     0     0     0     0
  
 
## for easier cutting use Hmisc library 
 > library(Hmisc)
 > restData$zipGroups = cut2(restData$zipCode, g=4)
> table(restData$zipGroups)

[-21226,21205) [ 21205,21220) [ 21220,21227) [ 21227,21287] 
           338            375            300            314 
> 

## creating factor variable
> restData$zcf = factor(restData$zipCode)
> restData$zcf[1:10]
 [1] 21206 21231 21224 21211 21223 21218 21205 21211 21205 21231
32 Levels: -21226 21201 21202 21205 21206 21207 21208 21209 21210 ... 21287
> class(restData$zcf)
[1] "factor"
> 
## levels of factor variables
> yesno = sample(c("yes", "no"), size=10, replace = TRUE)
> yesno
 [1] "yes" "no"  "yes" "no"  "yes" "yes" "no"  "no"  "no"  "no" 
> yesnofac=factor(yesno, levels=c("yes", "no"))
> yesnofac
 [1] yes no  yes no  yes yes no  no  no  no 
Levels: yes no
> relevel(yesnofac, ref="yes")
 [1] yes no  yes no  yes yes no  no  no  no 
Levels: yes no
> as.numeric(yesnofac)
 [1] 1 2 1 2 1 1 2 2 2 2
> 

## mutate
> library(plyr)
> library(Hmisc)
> rerstData2= mutate(restData, zipGroups = cut2(zipCode, g=4)) ## new data.frame
> table(rerstData2$zipGroups)

[-21226,21205) [ 21205,21220) [ 21220,21227) [ 21227,21287] 
           338            375            300            314 
> 

## Common transforms

abs(x)
sqrt(x)
ceiling(x) 	## ceiling(3.475) = 4
floor(x)	## floor(3.475)	  = 30
round(x, digits=n)	## round(3.475,digits=2) = 3.48
signif(x, digits=n)	## signif(3.475, digits=2) = 3.50%
cos(x), sin(x)
log(x), log2(x), log10(x)
exp(x)


## ------------------------- Reshaping data ----------------------- ##

	Each variable froms a column
	Each observation forms a row
	Each table/file stores data about one kind of observation

> library(reshape2)
> head(mtcars)
                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

> mtcars$carname<-rownames(mtcars)
> head(mtcars)
                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
                            carname
Mazda RX4                 Mazda RX4
Mazda RX4 Wag         Mazda RX4 Wag
Datsun 710               Datsun 710
Hornet 4 Drive       Hornet 4 Drive
Hornet Sportabout Hornet Sportabout
Valiant                     Valiant

> carMelt<-melt(mtcars, id=c("carname", "gear", "cyl"), measure.vars=c("mpg", "hp")) ## 
> carMelt[carMelt$carname=="Mazda RX4",]
     carname gear cyl variable value
1  Mazda RX4    4   6      mpg    21
33 Mazda RX4    4   6       hp   110
> 

> cylData <- dcast(carMelt, cyl ~ variable) ## summarize data set
> cylData
  cyl mpg hp
1   4  11 11	
2   6   7  7
3   8  14 14
 
## dcast   - cast as data.frame
## acast   - cast as array (multidimensional)
## arrange - faster reordering without order() commands
## mutate  - adding new variables
> cylData <- dcast(carMelt, cyl ~ variable, mean); cylData		
  cyl      mpg        hp
1   4 26.66364  82.63636
2   6 19.74286 122.28571
3   8 15.10000 209.21429
> 


> head(InsectSprays)
  count spray
1    10     A
2     7     A
3    20     A
4    14     A
5    14     A
6    12     A

> tapply(InsectSprays$count, InsectSprays$spray, sum)	## sum count values for each unique spray value (A, B, ....) select sum(count), spray from InsectSprays group by spray
  A   B   C   D   E   F 
174 184  25  59  42 200 


## split, apply, combine
> spIns = split(InsectSprays$count, InsectSprays$spray);spIns; ## split by spray
$A
 [1] 10  7 20 14 14 12 10 23 17 20 14 13

$B
 [1] 11 17 21 11 16 14 17 17 19 21  7 13

$C
 [1] 0 1 7 2 3 1 2 1 3 0 1 4

$D
 [1]  3  5 12  6  4  3  5  5  5  5  2  4

$E
 [1] 3 5 3 5 3 6 1 1 3 2 6 4

$F
 [1] 11  9 15 22 15 16 13 10 26 26 24 13

> sprCount = lapply(spIns, sum); sprCount ## list apply

$A
[1] 174

$B
[1] 184

$C
[1] 25

$D
[1] 59

$E
[1] 42

$F
[1] 200

> unlist(sprCount)			## from list to vector
  A   B   C   D   E   F 
174 184  25  59  42 200 

> sapply(spIns, sum)		## apply + combine(unlist)
  A   B   C   D   E   F 
174 184  25  59  42 200 
> 

> library(plyr)
> ddply(InsectSprays, .(spray), summarize, sum=sum(count))	## plyr lib group by sum as data.frame
  spray sum
1     A 174
2     B 184
3     C  25
4     D  59
5     E  42
6     F 200

> spraySums <- ddply(InsectSprays, .(spray), summarize, sum=ave(count, FUN=sum))
> spraySums
   spray sum
1      A 174
2      A 174
3      A 174
4      A 174
5      A 174
6      A 174
7      A 174
8      A 174
9      A 174
10     A 174
11     A 174
12     A 174
13     B 184
14     B 184
15     B 184
16     B 184

## ------------------------------- dplyr ------------------------------ ##

	arrange		- reorder rows of data frame
	filter		- extract subset of rows from data frame base on logical condition
	select		- return subset of columns of data frame
	mutate		- add new variables/columns or transform existing variables
	rename		- rename variables in data frame
	summarize	- generate summary statistics of different variables in the data frame
	print 		- print to console

	dplyr works with:
						data.table ## large tables fast operations
						SQL via DBI package
	
> library(dplyr)	
> chicago<-readRDS(".\\data\\chicago.rds")
> dim(chicago)
[1] 6940    8
> str(chicago)
'data.frame':	6940 obs. of  8 variables:
 $ city      : chr  "chic" "chic" "chic" "chic" ...
 $ tmpd      : num  31.5 33 33 29 32 40 34.5 29 26.5 32.5 ...
 $ dptp      : num  31.5 29.9 27.4 28.6 28.9 ...
 $ date      : Date, format: "1987-01-01" "1987-01-02" ...
 $ pm25tmean2: num  NA NA NA NA NA NA NA NA NA NA ...
 $ pm10tmean2: num  34 NA 34.2 47 NA ...
 $ o3tmean2  : num  4.25 3.3 3.33 4.38 4.75 ...
 $ no2tmean2 : num  20 23.2 23.8 30.4 30.3 ...
 
> names(chicago)
[1] "city"       "tmpd"       "dptp"       "date"       "pm25tmean2"
[6] "pm10tmean2" "o3tmean2"   "no2tmean2" 

> head(select(chicago, city:dptp)) 		## columns city, dptp and between
  city tmpd   dptp
1 chic 31.5 31.500
2 chic 33.0 29.875
3 chic 33.0 27.375
4 chic 29.0 28.625
5 chic 32.0 28.875
6 chic 40.0 35.125

> head(select(chicago, -(city:dptp)))	## all columns except city, dptp and between
        date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
1 1987-01-01         NA   34.00000 4.250000  19.98810
2 1987-01-02         NA         NA 3.304348  23.19099
3 1987-01-03         NA   34.16667 3.333333  23.81548
4 1987-01-04         NA   47.00000 4.375000  30.43452
5 1987-01-05         NA         NA 4.750000  30.33333
6 1987-01-06         NA   48.00000 5.833333  25.77233

## equivalent to head(select(chicago, -(city:dptp)))
> i<-match("city", names(chicago))
> j<-match("dptp", names(chicago))
> head(chicago[, -(i:j)])
        date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
1 1987-01-01         NA   34.00000 4.250000  19.98810
2 1987-01-02         NA         NA 3.304348  23.19099
3 1987-01-03         NA   34.16667 3.333333  23.81548
4 1987-01-04         NA   47.00000 4.375000  30.43452
5 1987-01-05         NA         NA 4.750000  30.33333
6 1987-01-06         NA   48.00000 5.833333  25.77233

## filter all rows where pm25tmean2 > 30
> chic.f <- filter(chicago, pm25tmean2 > 30)
> head(chic.f)
  city tmpd dptp       date pm25tmean2 pm10tmean2  o3tmean2 no2tmean2
1 chic   23 21.9 1998-01-17      38.10   32.46154  3.180556  25.30000
2 chic   28 25.8 1998-01-23      33.95   38.69231  1.750000  29.37630
3 chic   55 51.3 1998-04-30      39.40   34.00000 10.786232  25.31310
4 chic   59 53.7 1998-05-01      35.40   28.50000 14.295125  31.42905
5 chic   57 52.0 1998-05-02      33.30   35.00000 20.662879  26.79861
6 chic   57 56.0 1998-05-07      32.10   34.50000 24.270422  33.99167

## filter with multiple conditions
> chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80); head(chic.f)
  city tmpd dptp       date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
1 chic   81 71.2 1998-08-23    39.6000       59.0 45.86364  14.32639
2 chic   81 70.4 1998-09-06    31.5000       50.5 50.66250  20.31250
3 chic   82 72.2 2001-07-20    32.3000       58.5 33.00380  33.67500
4 chic   84 72.9 2001-08-01    43.7000       81.5 45.17736  27.44239
5 chic   85 72.6 2001-08-08    38.8375       70.0 37.98047  27.62743
6 chic   84 72.6 2001-08-09    38.2000       66.0 36.73245  26.46742

## arrange - order by date
> chicago = arrange(chicago, date); head(chicago)
  city tmpd   dptp       date pm25tmean2 pm10tmean2 o3tmean2 no2tmean2
1 chic 31.5 31.500 1987-01-01         NA   34.00000 4.250000  19.98810
2 chic 33.0 29.875 1987-01-02         NA         NA 3.304348  23.19099
3 chic 33.0 27.375 1987-01-03         NA   34.16667 3.333333  23.81548
4 chic 29.0 28.625 1987-01-04         NA   47.00000 4.375000  30.43452
5 chic 32.0 28.875 1987-01-05         NA         NA 4.750000  30.33333
6 chic 40.0 35.125 1987-01-06         NA   48.00000 5.833333  25.77233

## arrange with descending order
> chicago = arrange(chicago, desc(date))

## columns renamed
> chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
> head(chicago)
  city tmpd dewpoint       date     pm25 pm10tmean2  o3tmean2 no2tmean2
1 chic   35     30.1 2005-12-31 15.00000       23.5  2.531250  13.25000
2 chic   36     31.0 2005-12-30 15.05714       19.2  3.034420  22.80556
3 chic   35     29.4 2005-12-29  7.45000       23.5  6.794837  19.97222
4 chic   37     34.5 2005-12-28 17.75000       27.5  3.260417  19.28563
5 chic   40     33.6 2005-12-27 23.56000       27.0  4.468750  23.50000
6 chic   35     29.6 2005-12-26  8.40000        8.5 14.041667  16.81944

## creates new variable. pm25dtrend is created
> chicago<-mutate(chicago, pm25dtrend=pm25-mean(pm25, na.rm=TRUE))
> head(select(chicago, pm25, pm25dtrend))
      pm25 pm25dtrend
1 15.00000  -1.230958
2 15.05714  -1.173815
3  7.45000  -8.780958
4 17.75000   1.519042
5 23.56000   7.329042
6  8.40000  -7.830958

## add factor, hot (tmpd>80) or cold (tmpd<=80)
> chicago<-mutate(chicago, tempcat=factor(1*(tmpd>80), labels=c("cold", "hot")))
> hotcold <-group_by(chicago, tempcat)
> hotcold
Source: local data frame [6,940 x 10]
Groups: tempcat

   city tmpd dewpoint       date     pm25 pm10tmean2  o3tmean2 no2tmean2 pm25dtrend tempcat
1  chic   35     30.1 2005-12-31 15.00000       23.5  2.531250  13.25000  -1.230958    cold
2  chic   36     31.0 2005-12-30 15.05714       19.2  3.034420  22.80556  -1.173815    cold
3  chic   35     29.4 2005-12-29  7.45000       23.5  6.794837  19.97222  -8.780958    cold
4  chic   37     34.5 2005-12-28 17.75000       27.5  3.260417  19.28563   1.519042    cold
5  chic   40     33.6 2005-12-27 23.56000       27.0  4.468750  23.50000   7.329042    cold
6  chic   35     29.6 2005-12-26  8.40000        8.5 14.041667  16.81944  -7.830958    cold
7  chic   35     32.1 2005-12-25  6.70000        8.0 14.354167  13.79167  -9.530958    cold
8  chic   37     35.2 2005-12-24 30.77143       25.2  1.770833  31.98611  14.540471    cold
9  chic   41     32.6 2005-12-23 32.90000       34.5  6.906250  29.08333  16.669042    cold
10 chic   22     23.3 2005-12-22 36.65000       42.5  5.385417  33.73026  20.419042    cold
..  ...  ...      ...        ...      ...        ...       ...       ...        ...     ...

> summarize(hotcold)
Source: local data frame [3 x 1]

  tempcat
1    cold
2     hot
3      NA
> summarize(hotcold, pm25=mean(pm25), o3=max(o3tmean2), no2 = median(no2tmean2))
Source: local data frame [3 x 4]

  tempcat    pm25        o3      no2
1    cold      NA 66.587500 24.54924
2     hot      NA 62.969656 24.93870
3      NA 47.7375  9.416667 37.44444

> summarize(hotcold, pm25=mean(pm25, na.rm=TRUE), o3=max(o3tmean2), no2 = median(no2tmean2))
Source: local data frame [3 x 4]

  tempcat     pm25        o3      no2
1    cold 15.97807 66.587500 24.54924
2     hot 26.48118 62.969656 24.93870
3      NA 47.73750  9.416667 37.44444

> chicago <- mutate(chicago, year = as.POSIXlt(date)$year+1900)
> years<-group_by(chicago, year)
> summarize(years, pm25=mean(pm25, na.rm=TRUE), o3=max(o3tmean2), no2 = median(no2tmean2))
Source: local data frame [19 x 4]

   year     pm25       o3      no2
1  1987      NaN 62.96966 23.49369
2  1988      NaN 61.67708 24.52296
3  1989      NaN 59.72727 26.14062
4  1990      NaN 52.22917 22.59583
5  1991      NaN 63.10417 21.38194
6  1992      NaN 50.82870 24.78921
7  1993      NaN 44.30093 25.76993
8  1994      NaN 52.17844 28.47500
9  1995      NaN 66.58750 27.26042
10 1996      NaN 58.39583 26.38715
11 1997      NaN 56.54167 25.48143
12 1998 18.26467 50.66250 24.58649
13 1999 18.49646 57.48864 24.66667
14 2000 16.93806 55.76103 23.46082
15 2001 16.92632 51.81984 25.06522
16 2002 15.27335 54.88043 22.73750
17 2003 15.23183 56.16608 24.62500
18 2004 14.62864 44.48240 23.39130
19 2005 16.18556 58.84126 22.62387
> 

## pipeline of operators
> chicago %>% mutate(month = as.POSIXlt(date)$mon+1) %>% group_by(month) %>% summarize(pm25 = mean(pm25, na.rm=TRUE), o3 = max(o3tmean2), no2=median(no2tmean2))
Source: local data frame [12 x 4]

   month     pm25       o3      no2
1      1 17.76996 28.22222 25.35417
2      2 20.37513 37.37500 26.78034
3      3 17.40818 39.05000 26.76984
4      4 13.85879 47.94907 25.03125
5      5 14.07420 52.75000 24.22222
6      6 15.86461 66.58750 25.01140
7      7 16.57087 59.54167 22.38442
8      8 16.93380 53.96701 22.98333
9      9 15.91279 57.48864 24.47917
10    10 14.23557 47.09275 24.15217
11    11 15.15794 29.45833 23.56537
12    12 17.52221 27.70833 24.45773
> 

## ------------------------------ Merging data -------------------------------- ##

> fileUrl1 <- "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
> fileUrl2 <- "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
> download.file(fileUrl1, destfile=".\\data\\reviews.csv")
> download.file(fileUrl2, destfile=".\\data\\solutions.csv")
> reviews = read.csv(".\\data\\reviews.csv")
> solutions = read.csv(".\\data\\solutions.csv")

> head(reviews, 2)
  id solution_id reviewer_id      start       stop time_left accept
1  1           3          27 1304095698 1304095758      1754      1
2  2           4          22 1304095188 1304095206      2306      1
> head(solutions, 2)
  id problem_id subject_id      start       stop time_left answer
1  1        156         29 1304095119 1304095169      2343      B
2  2        269         25 1304095119 1304095183      2329      C
> 

> names(reviews)
[1] "id"          "solution_id" "reviewer_id" "start"       "stop"       
[6] "time_left"   "accept"     
> names(solutions)
[1] "id"         "problem_id" "subject_id" "start"      "stop"      
[6] "time_left"  "answer"    
> 

## default !!! merge is done by the same name columns

> mergedData = merge(reviews, solutions, by.x="solution_id", by.y="id", all=TRUE) ## all = TRUE - equivalent LEFT JOIN
> head(mergedData)
  solution_id id reviewer_id    start.x     stop.x time_left.x accept
1           1  4          26 1304095267 1304095423        2089      1
2           2  6          29 1304095471 1304095513        1999      1
3           3  1          27 1304095698 1304095758        1754      1
4           4  2          22 1304095188 1304095206        2306      1
5           5  3          28 1304095276 1304095320        2192      1
6           6 16          22 1304095303 1304095471        2041      1
  problem_id subject_id    start.y     stop.y time_left.y answer
1        156         29 1304095119 1304095169        2343      B
2        269         25 1304095119 1304095183        2329      C
3         34         22 1304095127 1304095146        2366      C
4         19         23 1304095127 1304095150        2362      D
5        605         26 1304095127 1304095167        2345      A
6        384         27 1304095131 1304095270        2242      C
> 

## intersect function
> intersect(names(solutions), names(reviews))
[1] "id"        "start"     "stop"      "time_left"

## plyr join, faster than merge, but less featured. By default joins on the columns with the same name ##
> df1 = data.frame(id=sample(1:10), x= rnorm(10))
> df2 = data.frame(id=sample(1:10), y= rnorm(10))
> df1
   id            x
1   4  0.111176888
2   7 -0.232574939
3   8  1.314259350
4  10  0.002548925
5   2  0.601768511
6   6 -0.936685420
7   3  0.088483718
8   5 -0.137282627
9   9  0.771657655
10  1 -1.183505798
> df2
   id          y
1   7  1.0817537
2   4  1.1693145
3   2 -0.6966556
4   9  1.9204826
5   5 -1.7915157
6   1 -0.3195369
7   8  1.7856156
8   3  0.2461708
9  10 -0.8068337
10  6  1.3541107
> arrange(join(df1, df2), id)
Joining by: id
   id            x          y
1   1 -1.183505798 -0.3195369
2   2  0.601768511 -0.6966556
3   3  0.088483718  0.2461708
4   4  0.111176888  1.1693145
5   5 -0.137282627 -1.7915157
6   6 -0.936685420  1.3541107
7   7 -0.232574939  1.0817537
8   8  1.314259350  1.7856156
9   9  0.771657655  1.9204826
10 10  0.002548925 -0.8068337
> 

## join multiple data frames !!! ##
> df1 = data.frame(id=sample(1:10), x= rnorm(10))
> df2 = data.frame(id=sample(1:10), y= rnorm(10))
> df3 = data.frame(id=sample(1:10), z= rnorm(10))
> dfList <- list(df1, df2, df3)
> dfList
[[1]]
   id            x
1   4  0.111176888
2   7 -0.232574939
3   8  1.314259350
4  10  0.002548925
5   2  0.601768511
6   6 -0.936685420
7   3  0.088483718
8   5 -0.137282627
9   9  0.771657655
10  1 -1.183505798

[[2]]
   id          y
1   7  1.0817537
2   4  1.1693145
3   2 -0.6966556
4   9  1.9204826
5   5 -1.7915157
6   1 -0.3195369
7   8  1.7856156
8   3  0.2461708
9  10 -0.8068337
10  6  1.3541107

[[3]]
   id            z
1   5  0.243214831
2   6 -0.191895045
3   9  0.027075766
4  10 -0.405347936
5   8 -1.450620309
6   2  1.604840079
7   4 -0.406691110
8   7 -0.006086678
9   1 -0.554252751
10  3  0.587256574

> join_all(dfList)
Joining by: id
Joining by: id
   id            x          y            z
1   4  0.111176888  1.1693145 -0.406691110
2   7 -0.232574939  1.0817537 -0.006086678
3   8  1.314259350  1.7856156 -1.450620309
4  10  0.002548925 -0.8068337 -0.405347936
5   2  0.601768511 -0.6966556  1.604840079
6   6 -0.936685420  1.3541107 -0.191895045
7   3  0.088483718  0.2461708  0.587256574
8   5 -0.137282627 -1.7915157  0.243214831
9   9  0.771657655  1.9204826  0.027075766
10  1 -1.183505798 -0.3195369 -0.554252751
> 
